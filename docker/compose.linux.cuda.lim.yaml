services:
  LIM:
    image: LIM/cuda12.4-cudnn9
    container_name: LIM_docker
    runtime: nvidia  # Use the NVIDIA runtime
    deploy:
      resources:
          reservations:
            devices:
              - driver: nvidia
                count: all
                capabilities: [gpu, compute, utility, graphics]

    ipc: "host"
    network_mode: 'host'
    cap_add:
      - "SYS_PTRACE"
    security_opt:
      - "seccomp=unconfined"
    shm_size: "8G"
    volumes:
      - "..:/dockerx/LIM"
      - "/tmp/.X11-unix:/tmp/.X11-unix"  # Share the X11 socket with the container
      - "${HOME}/.Xauthority:/root/.Xauthority:ro" # Mount Xauthority
      - type: bind
        source: /home/fmolina/code/Tesis/src/LIM/data
        target: /dockerx/LIM/data/
    working_dir: "/dockerx/LIM"
    entrypoint: "/dockerx/LIM/scripts/entrypoint.sh /bin/bash"
    stdin_open: true
    tty: true
    environment:
      - DISPLAY=${DISPLAY}
      - XAUTHORITY=/root/.Xauthority  # Set the Xauthority path explicitly
      - XDG_RUNTIME_DIR=/tmp/runtime-root
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
      - HSA_OVERRIDE_GFX_VERSION=10.3.0